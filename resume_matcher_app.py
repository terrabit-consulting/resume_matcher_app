import openai
import streamlit as st
import time
import fitz  # PyMuPDF
import docx
import pandas as pd
import re
import io
import spacy
from PyPDF2 import PdfReader

# Load spaCy model
nlp = spacy.load("en_core_web_sm")

# ‚úÖ OpenAI Client
client = openai.OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# ‚úÖ GPT Fallback Logic
def call_gpt_with_fallback(prompt):
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.warning(f"‚ö†Ô∏è GPT-4o failed: {str(e)}. Falling back to GPT-3.5...")
        time.sleep(1)
        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0
            )
            return response.choices[0].message.content.strip()
        except Exception as e2:
            st.error(f"‚ùå GPT failed. {str(e2)}")
            return "‚ö†Ô∏è GPT processing failed."

# ‚úÖ File Readers
def read_pdf(file):
    text = ""
    pdf_reader = PdfReader(file)
    for page in pdf_reader.pages:
        if page.extract_text():
            text += page.extract_text()
    return text

def read_docx(file):
    doc = docx.Document(file)
    return "\n".join([para.text for para in doc.paragraphs])

def read_file(file):
    if file.type == "application/pdf":
        return read_pdf(file)
    elif file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        return read_docx(file)
    else:
        return file.read().decode("utf-8", errors="ignore")

# ‚úÖ Enhanced Name Extraction
def extract_candidate_name(resume_text, filename):
    lines = [line.strip() for line in resume_text.splitlines() if line.strip()]
    candidate_lines = lines[:10] + lines[-10:]

    name_patterns = [
        r"(resume of[:\-]?)\s*(.+)", r"(cv of[:\-]?)\s*(.+)", r"(name[:\-]?)\s*(.+)", r"(full name[:\-]?)\s*(.+)"
    ]
    for line in candidate_lines:
        for pattern in name_patterns:
            match = re.search(pattern, line.lower(), re.IGNORECASE)
            if match:
                name = match.group(2).strip()
                if 2 <= len(name.split()) <= 4 and all(w[0].isupper() for w in name.split() if w.isalpha()):
                    return name.title()

    doc = nlp("\n".join(candidate_lines))
    person_names = [ent.text.strip() for ent in doc.ents if ent.label_ == "PERSON" and 2 <= len(ent.text.split()) <= 4]
    if person_names:
        return person_names[0].title()

    name = filename.replace(".docx", "").replace(".pdf", "").replace(".txt", "")
    name = re.sub(r"[_\-.]", " ", name)
    name = re.sub(r"\b(Resume|CV|Terrabit Consulting|ID \d+|Backend|Developer|Engineer|SW|Resources|Center|Hubware|V\d+)\b", "", name, flags=re.I)
    name = re.sub(r"\s+", " ", name)
    return name.strip().title()

# ‚úÖ Resume Comparison with GPT
def compare_resume(jd_text, resume_text, candidate_name):
    prompt = f"""
You are a Recruiter Assistant bot.

Compare the following resume to the job description and return the result in the following format:

üíº **Name**: {candidate_name}
‚úÖ **Score**: [Match Score]%

üîß **Reason**:
- ‚ö†Ô∏è **Role Match**: (Brief explanation)
- ‚úÖ **Skill Match**: (Matched or missing skills)
- ‚ùå **Major Gaps**: (What is completely missing or irrelevant)

‚ö†Ô∏è **Warning**: Add only if score < 70%

Job Description:
{jd_text}

Resume:
{resume_text}
"""
    return call_gpt_with_fallback(prompt)

# ‚úÖ Follow-up Message Generator
def generate_followup(jd_text, resume_text):
    prompt = f"""
Based on the resume and job description below, generate:
1. üì± WhatsApp message (casual)
2. üìß Email message (formal)
3. üß† Screening questions (3-5)

Job Description:
{jd_text}

Resume:
{resume_text}
"""
    return call_gpt_with_fallback(prompt)

# ‚úÖ Streamlit UI
st.set_page_config(page_title="Resume Matcher GPT", layout="centered")
st.title("ü§ñ Resume Matcher Bot (GPT-4o ‚Üí 3.5 fallback)")
st.write("Upload a JD and multiple resumes. Get match scores, red flags, and follow-up messaging.")

# Session State
if "results" not in st.session_state:
    st.session_state["results"] = []
if "processed_resumes" not in st.session_state:
    st.session_state["processed_resumes"] = set()
if "jd_text" not in st.session_state:
    st.session_state["jd_text"] = ""
if "jd_file" not in st.session_state:
    st.session_state["jd_file"] = None

# Reset Button
if st.button("üîÑ Start New Matching Session"):
    st.session_state.clear()
    st.rerun()

# Upload JD and Resumes
jd_file = st.file_uploader("üìå Upload Job Description", type=["txt", "pdf", "docx"], key="jd_uploader")
resume_files = st.file_uploader("üìÑ Upload Candidate Resumes", type=["txt", "pdf", "docx"], accept_multiple_files=True, key="resume_uploader")

if jd_file and not st.session_state.get("jd_text"):
    st.session_state["jd_text"] = read_file(jd_file)
    st.session_state["jd_file"] = jd_file.name

jd_text = st.session_state.get("jd_text", "")

# Run Matching
if st.button("‚ñ∂Ô∏è Run Matching") and jd_text and resume_files:
    for resume_file in resume_files:
        if resume_file.name in st.session_state["processed_resumes"]:
            continue
        resume_text = read_file(resume_file)
        candidate_name = extract_candidate_name(resume_text, resume_file.name)

        with st.spinner(f"üîç Analyzing {candidate_name}..."):
            result = compare_resume(jd_text, resume_text, candidate_name)

        score_match = re.search(r"Score\*\*: \**([0-9]+)%", result)
        score = int(score_match.group(1)) if score_match else 0

        st.session_state["results"].append({
            "name": candidate_name,
            "score": score,
            "result": result,
            "resume_text": resume_text
        })
        st.session_state["processed_resumes"].add(resume_file.name)

# ‚úÖ Results Display
summary = []
for entry in st.session_state["results"]:
    st.markdown("---")
    st.subheader(f"üíº {entry['name']}")
    st.markdown(entry["result"])

    score = entry["score"]
    if score < 50:
        st.error("‚ùå Not suitable ‚Äì Major role mismatch")
    elif score < 70:
        st.warning("‚ö†Ô∏è Consider with caution ‚Äì Some relevant experience but lacks core skills")
    else:
        st.success("‚úÖ Strong match ‚Äì Good alignment with JD")

    summary.append({"Candidate": entry["name"], "Score": score})

    if st.button(f"üì© Generate Follow-up for {entry['name']}", key=f"followup_{entry['name']}"):
        with st.spinner("Generating messages..."):
            followup = generate_followup(jd_text, entry["resume_text"])
            st.markdown("---")
            st.markdown(followup)

# ‚úÖ Summary Table + Excel Export
if summary:
    st.markdown("### üìä Summary of All Candidates")
    df_summary = pd.DataFrame(summary).sort_values(by="Score", ascending=False)
    st.dataframe(df_summary)

    excel_buffer = io.BytesIO()
    with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
        df_summary.to_excel(writer, index=False)

    st.download_button(
        label="üì• Download Summary as Excel",
        data=excel_buffer.getvalue(),
        file_name="resume_match_summary.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
